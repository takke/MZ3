.JRegex高速化

JRegexは遅い、高速化についてナニも考慮せず作ったんだから 間 違 い な い!

NFA版の一番のボトルネックは jreg_scan_node の再帰呼び出し
DFA版の一番のボトルネックは 決定性を都度評価し求めるところ、、、かな?

..NFA版の改善
make prof, make profu してみると
jreg_scan_node 関数にほぼ全ての原因があるのが分かる

NFAの核となる部分なので、この関数では大雑把な調整しかできない
たとえば、、、
  ノードの最適化による間接的な jreg_scan_node 呼び出しの低減
  先読みを利用した分岐の削除による再帰呼び出しの低減
いずれもあまり効果的ではなさそう

そこでアルゴリズム自体の改善として以下を用いる
  先頭文字が固定のときBM法の適用 (無条件の適用が可能か)
  後方参照を必要としない時、自動的にDFAの適用 (コンパイルオプション拡張?)

  (2004/04/20 追記、BM法を組み込んでみた、まだ補助に使っているだけというカンジだが
              サクラエディタに組み込んでGREPしたところかなり改善されてる模様)

..DFA版の改善
DFAでは(実際DFAじゃないんだけど)、完全に遷移テーブルを作成することが効果あるか?
アルゴリズムとしては最悪 O(M*N) になるとは思うが N を小さくする事が最良なのかな?
NFA版と同じくBM法を適用しある程度のふるいにかけることは可能

DFAのアルゴリズムとしては↓の繰り返し
理想 現在の状況(N)  * 入力文字(C) = 次の状態(E)
現在 現在の状況(Nn) * 入力文字(C) = 次の状態(En) # 複数の状態集合をまとめて扱っている

現在、各ビットが状態番号になっている
入力文字(c)に対しとりうる状態のビット(G)と現在の状態(N)を比較し、次の遷移先(e)を求める
  # N = e[N & G[c]]; // イメージ
現在のDFA(もどき)では N, e, c は用意されているので G を新たに作る
ただし e[N] には0文字幅遷移が入りそうにないので現状のDFA(もどき)と住み分ける必要があるかな

Gの大きさ、eの大きさ
単純に考えると状態数をnとするときGは 2のn乗ビット の要素を cの最大値 個
                                 eは 2のn乗ビット の要素を nの2乗    個
UNICODE(UCS-2)の場合cは 2^16、状態数を10としても
  int G[65536][32]; // 8MB (UCS-4だと512GB)
  int e[100][32];   // 12.5KB
だけ用意すればよい、非常にバカバカしいのでBMPを用いること

.JChar依存のUNICODE対応
UNICODE対応はJChar、、、Windows環境のtchar.hに頼っている
I18Nはまぁ、コレでいいとしてM17Nについては全く考えていない
現状ソースに文字列を直にかいているためGCCでどーにもならない
コンパイラがワイド文字列をUCS-2(WindowsってUTF-16?)にしてくれないとI18Nすらままならない

# つか、なんや、GCCのよく分からない対応
# wchar_t c = L"あ"; がなんで1バイトだけをwchar_tにする、、、

多言語対応するためにも _T("") をやめる事 tchar.h をやめる (環境依存をさける)
t_code, w_code を wchar_t で統一する(分かりやすさの為)

